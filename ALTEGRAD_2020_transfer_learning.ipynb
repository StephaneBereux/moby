{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ALTEGRAD_2020_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StephaneBereux/moby/blob/master/ALTEGRAD_2020_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "# Transfer learning for NLP\n",
        "## ALTEGRAD - Lab session 3\n",
        "#### Moussa Kamal Eddine, Hadi Abdine (Dascim LIX)\n",
        "##### November 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "outputId": "62b8b7e8-9781-44f6-b7ed-291abaf39d11"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# upload external file before import\n",
        "from google.colab import files\n",
        "#device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b05b11be-5252-4b16-88a7-721c8fafa2d6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b05b11be-5252-4b16-88a7-721c8fafa2d6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntokens,nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid,dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid,nhead,nhid,dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses) \n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.base.forward(src, src_mask)\n",
        "        output = self.classifier.forward(x)\n",
        "        return output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177e2b76-321d-4022-a30a-058fd0c22eb5"
      },
      "source": [
        "ntokens = 100 #fill me # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk7Hk1k3WBdR",
        "outputId": "68c3a277-3bec-4c54-a3d5-51f31a108e87"
      },
      "source": [
        "model.named_parameters"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.named_parameters of Model(\n",
              "  (base): TransformerModel(\n",
              "    (encoder): Embedding(100, 200)\n",
              "    (pos_encoder): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (transformer_encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0, inplace=False)\n",
              "          (dropout2): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0, inplace=False)\n",
              "          (dropout2): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0, inplace=False)\n",
              "          (dropout2): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "        (3): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=200, out_features=200, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (dropout): Dropout(p=0, inplace=False)\n",
              "          (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
              "          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0, inplace=False)\n",
              "          (dropout2): Dropout(p=0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ClassificationHead(\n",
              "    (decoder): Linear(in_features=200, out_features=100, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24983341-c14a-4ab2-c2b3-844209c0d2e6"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 12:48:37--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-12-09 12:48:37 (19.1 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f040195-8f89-4c05-c3d2-f19c6cc0b300"
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        #word = line.split()[0].strip('▁') # ?\n",
        "        token2ind[word] = 4 + idx  #fill me\n",
        "\n",
        "ind2token = dict((v, k) for k, v in token2ind.items()) #fill me\n",
        "\n",
        "print(ind2token[1111])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▁trop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            self.token2ind[word] if word in self.token2ind else self.token2ind[\"<oov>\"]\n",
        "            for word in sequence[: self.max_len]\n",
        "        ]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1] #fill me \n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1] #fill me\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        loss.backward()\n",
        "        #fill me step 3\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "        optimizer.step()\n",
        "        #fill me step 4\n",
        "\n",
        "        total_loss += loss.item() \n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "source": [
        "ntokens = len(ind2token) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016d9b89-6f92-4e6b-a9c0-461461d97983"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 12:48:38--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  36.3MB/s    in 0.3s    \n",
            "\n",
            "2020-12-09 12:48:39 (36.3 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9737829-edf8-4e3d-93fd-c68c65b1535e"
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.30045 | ppl 1480.961\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.47870 | ppl  651.123\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.21179 | ppl  498.595\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.03961 | ppl  419.729\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.91429 | ppl  370.293\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.85202 | ppl  347.935\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.54035 | ppl  254.767\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.48501 | ppl  241.050\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.45402 | ppl  233.695\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.40672 | ppl  222.899\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.38785 | ppl  218.734\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.34498 | ppl  209.554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d33d2e9-ddfa-4106-bbf4-21cc2aeab383"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "#map_location=torch.device('cpu')\n",
        "#files.download('pretrained_model_4layers.pt')\n",
        "checkpoint = torch.load('./pretrained_model_4layers.pt') \n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict']) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 12:54:21--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   155MB/s    in 0.5s    \n",
            "\n",
            "2020-12-09 12:54:23 (155 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ef924b-7426-4003-ec17-be39ab902f70"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 7.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 12.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 16.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 9.7MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n",
            "--2020-12-09 12:54:27--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-12-09 12:54:27 (26.4 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces]\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1)\n",
        "    return next_token_ind, out\n",
        "    \n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    for i in range(max_len):\n",
        "        tok_idx, out = infer_next_token(sent)\n",
        "        tok = ind2token[tok_idx.item()]\n",
        "        word = s.decode_pieces([tok])\n",
        "        sent = '%s %s' % (sent, word)\n",
        "        if tok_idx.item() == token2ind['<eos>']:\n",
        "            break\n",
        "    return sent"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4514e3a-2e2d-4313-8dfc-c7765c5cd0fb"
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e2c82fe-71c6-4e2f-a2f4-70ea87d66992"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 12:54:27--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-12-09 12:54:27 (26.7 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2020-12-09 12:54:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-09 12:54:28 (53.6 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2020-12-09 12:54:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-12-09 12:54:28 (30.9 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2020-12-09 12:54:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-09 12:54:29 (70.8 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    acc = 0\n",
        "    model.eval()\n",
        "    for i, data in enumerate(data_loader):\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "        output = model(data[0].to(device), src_mask)[-1]\n",
        "        output = torch.argmax(output.view(-1, output.shape[-1]), 1) # The most probable\n",
        "        target = data[1].to(device)\n",
        "        acc += (target == output).sum().item()\n",
        "    acc = acc/len(data_loader.dataset)\n",
        "    return acc"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0188f50c-4fd1-490f-f841-cad549214e46"
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.78865 | ppl    2.200\n",
            "| epoch   1 |   100/  200 steps | loss 0.75824 | ppl    2.135\n",
            "| epoch   1 |   150/  200 steps | loss 0.70948 | ppl    2.033\n",
            "| epoch   2 |    50/  200 steps | loss 0.64300 | ppl    1.902\n",
            "| epoch   2 |   100/  200 steps | loss 0.61433 | ppl    1.848\n",
            "| epoch   2 |   150/  200 steps | loss 0.57359 | ppl    1.775\n",
            "| epoch   3 |    50/  200 steps | loss 0.46261 | ppl    1.588\n",
            "| epoch   3 |   100/  200 steps | loss 0.37403 | ppl    1.454\n",
            "| epoch   3 |   150/  200 steps | loss 0.38384 | ppl    1.468\n",
            "| epoch   4 |    50/  200 steps | loss 0.16512 | ppl    1.180\n",
            "| epoch   4 |   100/  200 steps | loss 0.15784 | ppl    1.171\n",
            "| epoch   4 |   150/  200 steps | loss 0.10537 | ppl    1.111\n",
            "| epoch   5 |    50/  200 steps | loss 0.04571 | ppl    1.047\n",
            "| epoch   5 |   100/  200 steps | loss 0.03189 | ppl    1.032\n",
            "| epoch   5 |   150/  200 steps | loss 0.04231 | ppl    1.043\n",
            "| epoch   6 |    50/  200 steps | loss 0.00465 | ppl    1.005\n",
            "| epoch   6 |   100/  200 steps | loss 0.01109 | ppl    1.011\n",
            "| epoch   6 |   150/  200 steps | loss 0.00173 | ppl    1.002\n",
            "| epoch   7 |    50/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00052 | ppl    1.001\n",
            "| epoch   7 |   150/  200 steps | loss 0.03648 | ppl    1.037\n",
            "| epoch   8 |    50/  200 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch   8 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00198 | ppl    1.002\n",
            "| epoch  12 |   150/  200 steps | loss 0.00036 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.76567 | ppl    2.150\n",
            "| epoch   1 |   100/  200 steps | loss 0.66787 | ppl    1.950\n",
            "| epoch   1 |   150/  200 steps | loss 0.53931 | ppl    1.715\n",
            "| epoch   2 |    50/  200 steps | loss 0.51544 | ppl    1.674\n",
            "| epoch   2 |   100/  200 steps | loss 0.48521 | ppl    1.625\n",
            "| epoch   2 |   150/  200 steps | loss 0.43509 | ppl    1.545\n",
            "| epoch   3 |    50/  200 steps | loss 0.44014 | ppl    1.553\n",
            "| epoch   3 |   100/  200 steps | loss 0.33508 | ppl    1.398\n",
            "| epoch   3 |   150/  200 steps | loss 0.35685 | ppl    1.429\n",
            "| epoch   4 |    50/  200 steps | loss 0.20421 | ppl    1.227\n",
            "| epoch   4 |   100/  200 steps | loss 0.25054 | ppl    1.285\n",
            "| epoch   4 |   150/  200 steps | loss 0.36175 | ppl    1.436\n",
            "| epoch   5 |    50/  200 steps | loss 0.18741 | ppl    1.206\n",
            "| epoch   5 |   100/  200 steps | loss 0.19096 | ppl    1.210\n",
            "| epoch   5 |   150/  200 steps | loss 0.17626 | ppl    1.193\n",
            "| epoch   6 |    50/  200 steps | loss 0.07908 | ppl    1.082\n",
            "| epoch   6 |   100/  200 steps | loss 0.10276 | ppl    1.108\n",
            "| epoch   6 |   150/  200 steps | loss 0.08287 | ppl    1.086\n",
            "| epoch   7 |    50/  200 steps | loss 0.01770 | ppl    1.018\n",
            "| epoch   7 |   100/  200 steps | loss 0.03972 | ppl    1.041\n",
            "| epoch   7 |   150/  200 steps | loss 0.03976 | ppl    1.041\n",
            "| epoch   8 |    50/  200 steps | loss 0.00223 | ppl    1.002\n",
            "| epoch   8 |   100/  200 steps | loss 0.01208 | ppl    1.012\n",
            "| epoch   8 |   150/  200 steps | loss 0.02945 | ppl    1.030\n",
            "| epoch   9 |    50/  200 steps | loss 0.00633 | ppl    1.006\n",
            "| epoch   9 |   100/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00738 | ppl    1.007\n",
            "| epoch  10 |    50/  200 steps | loss 0.00016 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00158 | ppl    1.002\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00015 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00623 | ppl    1.006\n",
            "| epoch  12 |   100/  200 steps | loss 0.00804 | ppl    1.008\n",
            "| epoch  12 |   150/  200 steps | loss 0.03907 | ppl    1.040\n",
            "| epoch  13 |    50/  200 steps | loss 0.00183 | ppl    1.002\n",
            "| epoch  13 |   100/  200 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.01601 | ppl    1.016\n",
            "| epoch  14 |   150/  200 steps | loss 0.00077 | ppl    1.001\n",
            "| epoch  15 |    50/  200 steps | loss 0.00967 | ppl    1.010\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.06136 | ppl    1.063\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "85315c3b-d245-45db-d40f-01848875dd25"
      },
      "source": [
        "#Visualize the accuracy\n",
        "\n",
        "epoch_index = np.arange(epochs)\n",
        "plt.plot(epoch_index, from_scratch_valid_acc, label='Transformer trained from scratch') \n",
        "plt.plot(epoch_index, pretrained_valid_acc, label='Pretrained transformer')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy according to the number of training epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}